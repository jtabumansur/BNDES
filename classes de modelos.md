| **Método** | **Objetivo Principal** | **Redução da Dimensionalidade** | **Foco** | **Pros vs Cons** | **Exemplos em Dados** |
|------------|------------------------|---------------------------------|----------|------------------|-----------------------|
| **PCA** | A diminuição de um dado, mantendo o maior número possível de variância. | Distribuição linear dos vetores próprios que explicam a variância. | A dimensionalidade comprimida está entre os vetores próprios. | <span style="color: green;">Simples, compressão de dados, melhor visualização.</span> <br> <span style="color: red;">Não distingue relações não lineares complicadas ou não alinhadas com os elementos.</span> | Identifica fatores-chave em dados financeiros, simplifica dados que mudam ao longo do tempo, ajudando a prever ou até mesmo influenciar o desempenho de um investimento. |
| **LDA** | A dimensionalidade dos dados deve maximizar a separação entre os elementos. | Distribuição linear dos vetores próprios que explicam os elementos. | Identificação de categorias de foco nítidas sem perda de propósito. | <span style="color: green;">Melhor compressão de dados para modelos supervisionados de classificação.</span> <br> <span style="color: red;">Pouca flexibilidade, requer dados rotulados.</span> | Identifica papéis ou padrões em categorias de risco, ajudando na tomada de decisão sobre investimentos, sugerindo estratégias cognitivas para riscos. |
| **Encoder** | Aprende representações eficientes dos dados e agrupa dados sem perdas. | Espaço latente sequencial sem restrições dos dados de entrada. | A diminuição de clusters de menor complexidade ou múltiplos grupos de dados. | <span style="color: green;">Capaz de reduzir a compressão e melhorar o aprendizado.</span> <br> <span style="color: red;">Pouca precisão na ordem de proximidade, agrupamentos de informação são opacos.</span> | Detecta fraudes e reduz ruídos em dados financeiros. Melhora a qualidade dos dados e a segurança na aplicação, diminuindo tempos e números. |
| **T-SNE** | Diminuir a dimensionalidade dos dados, movendo a distribuição local para avaliação de proximidade. | Componentes não lineares, manipulando vasto número de dados. | Visualização de dados críticos e padrões ocultos de proximidade em muitas camadas. | <span style="color: green;">Graduação visual de complexidade e proximidade, ótima para grandes quantidades de dados.</span> <br> <span style="color: red;">Alta complexidade, difícil de escalar para grandes datasets.</span> | Visualização de clusters em dados de clientes e produtos. Ideal para segmentação de padrões ocultos, ajudando na criação de estratégias de mercado e previsões. |
| **ICA** | Encontrar campos mais estatisticamente independentes. | Representa fontes independentes ocultas. | Descobrir elementos ocultos e interdependências dentro de dados multidimensionais. | <span style="color: green;">Identifica padrões independentes sem dependência linear.</span> <br> <span style="color: red;">Sensível a ruído, a complexidade pode afetar a integração.</span> | Separa influências independentes em transações, como padrões que afetam investimentos, erros críticos em performance, ajudando a descobrir novos insights. |